
from dotenv import load_dotenv

load_dotenv()

import streamlit as st
from langchain.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv
import os

# ç’°å¢ƒå¤‰æ•°ï¼ˆAPIã‚­ãƒ¼ï¼‰ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()

# ãƒ¢ãƒ‡ãƒ«ã®æº–å‚™ï¼ˆgpt-4oãªã©ã«å¤‰ãˆã¦ã‚‚OKï¼‰
llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.7)

# å°‚é–€å®¶ã”ã¨ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‰
expert_prompts = {
    "ç™»å±±ã®å°‚é–€å®¶": "ã‚ãªãŸã¯ç†Ÿç·´ã—ãŸç™»å±±ã‚¬ã‚¤ãƒ‰ã§ã™ã€‚ç™»å±±è€…ã«åˆ†ã‹ã‚Šã‚„ã™ãã€å®‰å…¨ã«é–¢ã™ã‚‹ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚„å±±ã®æƒ…å ±ã‚’ä¸å¯§ã«ä¼ãˆã¦ãã ã•ã„ã€‚",
    "åœ°çƒç§‘å­¦ã®å°‚é–€å®¶": "ã‚ãªãŸã¯åœ°çƒç§‘å­¦ã®å°‚é–€å®¶ã§ã™ã€‚åœ°è³ªã‚„æ°—è±¡ã€ç«å±±ã€åœ°éœ‡ãªã©ã«é–¢ã™ã‚‹è³ªå•ã«ã€å°‚é–€çš„ã‹ã¤ã‚„ã•ã—ã„è¨€è‘‰ã§ç­”ãˆã¦ãã ã•ã„ã€‚"
}

# å›ç­”ã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°
def generate_response(user_input, expert_type):
    system_prompt = expert_prompts.get(expert_type, "")
    
    template = """
    ä»¥ä¸‹ã®åˆ¶ç´„ã«å¾“ã£ã¦è³ªå•ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚
    
    [å°‚é–€å®¶ã¨ã—ã¦ã®æŒ‡é‡]
    {system_prompt}
    
    [ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•]
    {question}
    
    [å›ç­”]
    """

    prompt = PromptTemplate(
        input_variables=["system_prompt", "question"],
        template=template
    )

    final_prompt = prompt.format(system_prompt=system_prompt, question=user_input)
    
    return llm.invoke(final_prompt)

# --- Streamlit UI ---

st.title("ğŸ§  LLMã«èã„ã¦ã¿ã‚ˆã†ï¼")
st.markdown("ã“ã®ã‚¢ãƒ—ãƒªã§ã¯ã€ç™»å±±ã‚„åœ°çƒç§‘å­¦ã®å°‚é–€å®¶ã«ãªã‚Šãã£ãŸAIã«è³ªå•ã§ãã¾ã™ã€‚ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§å°‚é–€å®¶ã‚’é¸ã³ã€è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

# å°‚é–€å®¶ã®é¸æŠ
expert = st.radio("å°‚é–€å®¶ã‚’é¸ã‚“ã§ãã ã•ã„ï¼š", ["ç™»å±±ã®å°‚é–€å®¶", "åœ°çƒç§‘å­¦ã®å°‚é–€å®¶"])

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•
user_question = st.text_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", placeholder="ä¾‹ï¼šå¤ã«ãŠã™ã™ã‚ã®ç™»å±±ãƒ«ãƒ¼ãƒˆã¯ï¼Ÿ")

# ãƒœã‚¿ãƒ³ã§é€ä¿¡
if st.button("è³ªå•ã™ã‚‹"):
    if user_question.strip() == "":
        st.warning("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        with st.spinner("è€ƒãˆä¸­..."):
            answer = generate_response(user_question, expert)
            st.success("å›ç­”ãŒå±Šãã¾ã—ãŸï¼")
            st.write(answer.content)